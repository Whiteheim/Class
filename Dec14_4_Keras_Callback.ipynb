{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF7xa0HTNmPRWnKcLt8qJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whiteheim/WH/blob/main/Dec14_4_Keras_Callback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 콜백 (Callback)\n",
        "\n",
        "Model을 학습시킬 때 부가적으로 옵션을 넣어서 수행할 수 있도록 도와주는 객체\n",
        "\n",
        "모델 학습시 사용하는 fit()에 callbacks란느 파라미터로 지정 가능"
      ],
      "metadata": {
        "id": "WMO9P7SPjGPR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3bUOARWyi4Zs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras 내장 dataset에서 mnist 불러오기\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "pO89QnQrjgpy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data 정규화 0 ~ 1 사이로\n",
        "x_train = x_train / x_train.max()\n",
        "x_test = x_test / 255."
      ],
      "metadata": {
        "id": "Q9o0TcE4jzNA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model 생성\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    keras.layers.Dense(256, activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "ZJfU82Qbj717"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model complie\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZFeusI-QkTLv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 체크포인트 (Model Checkpoint)\n",
        "\n",
        "epoch(반복) 별로 model의 가중치를 저장하는 역할\n",
        "\n",
        "Checkpoint Hyper-Parameter\n",
        "  * filepath : 체크포인트를 저장하는 경로를 지엉\n",
        "  * sava_weights_only : 가중치만 저장할지 여부 (True, False)\n",
        "  * save_best_only : monitor 기준 가장 높은 epoch만 저장할지 or epoch마다 저장할지 여부 (True, False)\n",
        "  * monitor : 저장 시 기준이 되는 지표를 설정\n",
        "  * verbose : epoch마다 저장 여부를 알려주는 log message 출력 여부 (1(출력), 0(저장))\n",
        "  "
      ],
      "metadata": {
        "id": "OYfG9YIsklCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 체크포인트 설정\n",
        "checkPoint = keras.callbacks.ModelCheckpoint(\n",
        "    filepath='checkPoint.ckpt', # ckpt : 모델의 가중치 체크포인트 저장 파일\n",
        "    # tensorflow 모델 구조 자체는 제외한 가중치'만' 담고 있는 파일\n",
        "    # 이 파일을 통해 재학습이 가능, 불필요한 정보도 있어서 파일의 크기가 크고 무거움\n",
        "    save_wights_only=True,# 가중치만 저장\n",
        "    # False : 모델의 층 (layer), weights 모두 저장\n",
        "    save_best_only=True,\n",
        "    # True : monitor 되고 있는 값 기준으로 가장 뛰어난 epoch 모델이 저장\n",
        "    # False : epoch마다 모델이 filepath{epoch} 형태로 저장\n",
        "    monitor='val_loss', # model을 저장할 때, 기준이 되는 값을 지정\n",
        "    # Test_data_set을 기준으로 loss가 가장 적을 때 저장하려면 'val_loss'\n",
        "    # Trainning_data_set을 기준으로 loss가 가장 적을 때 저장하려면 'loss'\n",
        "    verbose=1 # 1 : 모델 저장시 문구가 뜸 / 0 : 모델 저장시 문구없이 저장만 됨\n",
        ")"
      ],
      "metadata": {
        "id": "dZjBdIUGliHv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train,\n",
        "          validation_data=(x_test, y_test),\n",
        "          epochs=10,\n",
        "          callbacks=[checkPoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEkl2nxvmzE9",
        "outputId": "2653b919-b7c4-4126-ceea-d922718f1406"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.2304 - accuracy: 0.9324\n",
            "Epoch 1: val_loss improved from inf to 0.10860, saving model to checkPoint.ckpt\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.2299 - accuracy: 0.9325 - val_loss: 0.1086 - val_accuracy: 0.9664\n",
            "Epoch 2/10\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0929 - accuracy: 0.9717\n",
            "Epoch 2: val_loss improved from 0.10860 to 0.10069, saving model to checkPoint.ckpt\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0929 - accuracy: 0.9717 - val_loss: 0.1007 - val_accuracy: 0.9697\n",
            "Epoch 3/10\n",
            "1873/1875 [============================>.] - ETA: 0s - loss: 0.0656 - accuracy: 0.9795\n",
            "Epoch 3: val_loss did not improve from 0.10069\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0656 - accuracy: 0.9795 - val_loss: 0.1099 - val_accuracy: 0.9668\n",
            "Epoch 4/10\n",
            "1863/1875 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9840\n",
            "Epoch 4: val_loss improved from 0.10069 to 0.06751, saving model to checkPoint.ckpt\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0500 - accuracy: 0.9840 - val_loss: 0.0675 - val_accuracy: 0.9806\n",
            "Epoch 5/10\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9877\n",
            "Epoch 5: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.0772 - val_accuracy: 0.9780\n",
            "Epoch 6/10\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9890\n",
            "Epoch 6: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0346 - accuracy: 0.9890 - val_loss: 0.0851 - val_accuracy: 0.9751\n",
            "Epoch 7/10\n",
            "1869/1875 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9907\n",
            "Epoch 7: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 0.0877 - val_accuracy: 0.9765\n",
            "Epoch 8/10\n",
            "1866/1875 [============================>.] - ETA: 0s - loss: 0.0240 - accuracy: 0.9921\n",
            "Epoch 8: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1002 - val_accuracy: 0.9766\n",
            "Epoch 9/10\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933\n",
            "Epoch 9: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9940\n",
            "Epoch 10: val_loss did not improve from 0.06751\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0189 - accuracy: 0.9940 - val_loss: 0.1054 - val_accuracy: 0.9761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdcbad69d00>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoint 적용 전 모델\n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print('loss : ', loss, 'accuracy : ', acc)\n",
        "\n",
        "# Checkpoint 적용 후 모델 \n",
        "model.load_weights('checkPoint.ckpt')\n",
        "# load_weights를 사용해서 불러오지 않으면, 저장된 가중치는 로드되지 않음 \n",
        "loss, acc = model.evaluate(x_test, y_test)\n",
        "print('loss : ', loss, 'accuracy : ', acc)\n",
        "\n",
        "# 모델 체크포인트에 저장된 가중치를 불러옸을 때는\n",
        "# 가장 검증손실이 낮았던 epoch 실행 후의 결과가 나옴\n",
        "# 검증손실이 가장 낮았던 모델 가중치를 사용할 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUmx4BcXnBqg",
        "outputId": "3b8805df-1aa2-47a7-afd5-1a5f80b83865"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1054 - accuracy: 0.9761\n",
            "loss :  0.10540500283241272 accuracy :  0.9761000275611877\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0675 - accuracy: 0.9806\n",
            "loss :  0.06751172244548798 accuracy :  0.9805999994277954\n"
          ]
        }
      ]
    }
  ]
}